{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests  \n",
    "from bs4 import BeautifulSoup  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''  \n",
    "URL of the archive web-page which provides link to  \n",
    "all video lectures.   \n",
    "First crawl the webpage to extract  \n",
    "all the links and then download videos.  \n",
    "'''\n",
    "  \n",
    "# specify the URL of the archive here  \n",
    "archive_url = \"http://www-personal.umich.edu/~csev/books/py4inf/media/\"\n",
    "  \n",
    "def get_video_links():  \n",
    "      \n",
    "    # create response object  \n",
    "    r = requests.get(archive_url)  \n",
    "      \n",
    "    # create beautiful-soup object  \n",
    "    soup = BeautifulSoup(r.content,'html5lib')  \n",
    "      \n",
    "    # find all links on web-page  \n",
    "    links = soup.findAll('a')  \n",
    "  \n",
    "    # filter the links ending with .mp4  \n",
    "    video_links = [archive_url + link['href'] for link in links if link['href'].endswith('mp4')]  \n",
    "  \n",
    "    return video_links      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_video_series(video_links):  \n",
    "  \n",
    "    for link in video_links:  \n",
    "  \n",
    "        '''iterate through all links in video_links  \n",
    "        and download them one by one'''\n",
    "          \n",
    "        # obtain filename by splitting url and getting  \n",
    "        # last string  \n",
    "        file_name = link.split('/')[-1]  \n",
    "  \n",
    "        print( \"Downloading file:%s\"%file_name)  \n",
    "          \n",
    "        # create response object  \n",
    "        r = requests.get(link, stream = True)  \n",
    "          \n",
    "        # download started  \n",
    "        with open(file_name, 'wb') as f:  \n",
    "            for chunk in r.iter_content(chunk_size = 1024*1024):  \n",
    "                if chunk:  \n",
    "                    f.write(chunk)  \n",
    "          \n",
    "        print( \"%s downloaded!\\n\"%file_name ) \n",
    "  \n",
    "    print (\"All videos downloaded!\") \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":  \n",
    "  \n",
    "    # getting all video links  \n",
    "    video_links = get_video_links()  \n",
    "  \n",
    "    # download all videos  \n",
    "    download_video_series(video_links)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
